{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540a0931-2d8e-4e91-9f6b-1687fe31d514",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "\n",
    "In this assignment, we'll finally work with some nonconjugate models. I will also introduce you to reparameterization techniques.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Please complete this Jupyter notebook and **don't** convert it to a `.py` file. Upload this notebook, along with any `.stan` files and any data sets as a `zip` file to Gradescope. \n",
    "\n",
    "Your work will be manually graded by our TA. There is no autograder for this assignment. For free response questions, feel free to add a markdown cell and type in there. Try to keep the preexisting structure as much as possible, and to be organized and label which cells correspond with which questions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e1c00-5fcb-401f-807e-22b96cd50dbc",
   "metadata": {},
   "source": [
    "### Problem 1: Poisson Data\n",
    "\n",
    "In the last assignment, we modeled a vector of counts $y = (y_1, \\ldots, y_n)$ using a multinomial distribution. \n",
    "\n",
    "Unlike last time, all of these counts will now assumed to be independent. Further, we can't reasonably put a bound on what each count could be. So, in this problem, we'll use a **Poisson likelihood**:\n",
    "\n",
    "$$\n",
    "L(y \\mid \\theta) = \\prod_{i=1}^n L(y_i \\mid \\theta) \\propto \\prod_{i=1}^n e^{-\\theta}\\theta^{y_i} = e^{-n\\theta}\\theta^{\\sum_i y_i}\n",
    "$$\n",
    "\n",
    "With this likelihood, $\\theta > 0$ is interpreted as a rate or average.\n",
    "\n",
    "The data can be found in `Road_Casualties_in_Great_Britain_1969___84_434_19.csv` Use the `DriversKilled` column only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622cdb8c-0585-4f5c-8f8b-158cd58ed359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "dk = pd.read_csv('Road_Casualties_in_Great_Britain_1969___84_434_19.csv').DriversKilled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31500b6f-1f05-45a7-ab21-ceb1e5d7a0d7",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "Name a conjugate prior for this likelihood! Write your single-word answer in Gradescope."
   ]
  },
  {
   "cell_type": "raw",
   "id": "27bcee0c-9708-4eba-92d7-de6fde591033",
   "metadata": {},
   "source": [
    "Gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85fc3d5-f387-4521-b0a0-e280921c5bd5",
   "metadata": {},
   "source": [
    "2.\n",
    "\n",
    "Suppose that the previous answer does not suite your needs, and that you want to use a lognormal prior! Pick a specific prior distribution (i.e. specify the hyperparameters), and describe a rationale as to why you chose them. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab54d41d-83fd-4a2d-bc4a-58567503e2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122.80208333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dk.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "417868f7-bb22-4e8c-a24c-49a62fce6955",
   "metadata": {},
   "source": [
    "I would use LogNormal(122, 9999) because the mean of the data we have is about 122 and I'm not really sure about it, so I chose an arbitrarily high standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e2c63-8838-47e1-8014-eda5b216d1ce",
   "metadata": {},
   "source": [
    "3.\n",
    "\n",
    "Use `stan` to estimate your model for the \"DriversKilled\" column. Please be sure to \n",
    "\n",
    " - report an $\\hat{R}$ diagnostic and comment on whether it is close to $1$\n",
    " - display trace plots of your samples obtained and comment on whether they look like \"fuzzy caterpillars.\"\n",
    "\n",
    "Then, after checking diagnostics...\n",
    "\n",
    " - display a histogram of the posterior for $\\theta$\n",
    " - report estimates of the mean, 5th and 95th percentiles of this posterior\n",
    " - comment on whether your posterior mean is close to the frequentist estimator of $\\theta$ (which is the sample mean of your data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0440595-6e84-46e1-b0c4-1ecb48c143ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to get source info for Stan model '/bml24/05/poisson_log_norm.stan'. Console:\nSyntax error in '/bml24/05/poisson_log_norm.stan', line 3, column 25 to column 26, parsing error:\n   -------------------------------------------------\n     1:  data {\n     2:    int<lower=0> N;           // number of data points\n     3:    array[N] int<lower=0> y[N];        // observed counts\n                                  ^\n     4:  }\n     5:  \n   -------------------------------------------------\n\n\";\" expected after variable declaration.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#import os\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#from cmdstanpy import CmdStanModel\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# bulid model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model_code \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoisson_log_norm.stan\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCmdStanModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstan_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# sample from model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m num_samps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/cmdstanpy/model.py:212\u001b[0m, in \u001b[0;36mCmdStanModel.__init__\u001b[0;34m(self, model_name, stan_file, exe_file, force_compile, stanc_options, cpp_options, user_header, compile)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cmdstan_version_before(\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m27\u001b[39m\n\u001b[1;32m    210\u001b[0m ):  \u001b[38;5;66;03m# unknown end of version range\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 212\u001b[0m         model_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_info:\n\u001b[1;32m    214\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fixed_param \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/cmdstanpy/model.py:318\u001b[0m, in \u001b[0;36mCmdStanModel.src_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m cmdstan_version_before(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m27\u001b[39m):\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstan_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compiler_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/cmdstanpy/compilation.py:361\u001b[0m, in \u001b[0;36msrc_info\u001b[0;34m(stan_file, compiler_options)\u001b[0m\n\u001b[1;32m    359\u001b[0m proc \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mreturncode:\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to get source info for Stan model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstan_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Console:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mproc\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m     )\n\u001b[1;32m    365\u001b[0m result: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(proc\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to get source info for Stan model '/bml24/05/poisson_log_norm.stan'. Console:\nSyntax error in '/bml24/05/poisson_log_norm.stan', line 3, column 25 to column 26, parsing error:\n   -------------------------------------------------\n     1:  data {\n     2:    int<lower=0> N;           // number of data points\n     3:    array[N] int<lower=0> y[N];        // observed counts\n                                  ^\n     4:  }\n     5:  \n   -------------------------------------------------\n\n\";\" expected after variable declaration.\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#from cmdstanpy import CmdStanModel\n",
    "\n",
    "# bulid model\n",
    "model_code = os.path.join('.', 'poisson_log_norm.stan')\n",
    "model = CmdStanModel(stan_file=model_code)\n",
    "\n",
    "# sample from model\n",
    "num_samps = 100\n",
    "normal_data = {'n' : num_samps, 'y': some_fake_data}\n",
    "fit = model.sample(normal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59ef4a-4560-49f8-a441-171ec4a76caf",
   "metadata": {},
   "source": [
    "4.\n",
    "\n",
    "Now use `stan` to estimate a slightly reparameterized model. Suppose you want to use a normal prior on an unconstrained parameter. Notice that if something is positive, then the (natural) log of it is unconstrained. Similarly, if something is unconstrained, the exponential of it is positive.\n",
    "\n",
    "Therefore, use the following model\n",
    "\n",
    "\n",
    "$$\n",
    "\\theta \\sim \\text{Normal}(a,b)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "y_i \\mid \\theta \\sim \\text{Poisson}(e^{\\theta})\n",
    "$$\n",
    "\n",
    "    \n",
    "Use `stan` to estimate your model for the \"DriversKilled\" column. Please be sure to \n",
    "\n",
    " - report an $\\hat{R}$ diagnostic and comment on whether it is close to $1$\n",
    " - display trace plots of your samples obtained and comment on whether they look like \"fuzzy caterpillars.\"\n",
    "\n",
    "Then, after checking diagnostics...\n",
    "\n",
    " - display a histogram of the posterior for $\\theta$\n",
    " - display a histogram of the posterior for the transformed parameter, too.\n",
    " - report estimates of the mean, 5th and 95th percentiles of the posterior of the unconstrained $\\theta$\n",
    " - comment on whether your posterior mean is close to the frequentist estimator (which is the sample mean of your data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab15444-391f-44be-b9ec-1a8fe5e3ddb9",
   "metadata": {},
   "source": [
    "### Problem 2: Binomial Data (again!)\n",
    "\n",
    "Suppose that you have $m > 1$ count data points $y_1, \\ldots, y_m$, each having a $\\text{Binomial}(n,\\eta)$ distribution. Assume further that they're all independent.\n",
    "\n",
    "Here $n$ is the maximum for each data point. $m$ is the number of data points.\n",
    "\n",
    "In our second homework we used the beta prior for the parameter that was bounded between $0$ and $1$. \n",
    "\n",
    "Now, you must use a normal prior for an unconstrained parameter. \n",
    "\n",
    "If $0 < \\eta < 1$, then the *logit* transformation is a way to make $-\\infty < \\theta < \\infty$ (unconstrained). Alternatively, if you have $\\eta$ that's unconstrained, then the `inv_logit` will squash the value to lie between $0$ and $1$.\n",
    "\n",
    "\n",
    "`stan` conveniently has a `logit()` and an `inv_logit()` function already made for you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8060401f-f342-461b-9267-35030e06404d",
   "metadata": {},
   "source": [
    "Use `stan` to estimate your model on any fictitious data you would like. Be sure to\n",
    "\n",
    " - report an $\\hat{R}$ diagnostic and comment on whether it is close to $1$\n",
    " - display trace plots of your samples obtained and comment on whether they look like \"fuzzy caterpillars.\"\n",
    "\n",
    "Then, after checking diagnostics...\n",
    "\n",
    " - display a histogram of the posterior for $\\theta$\n",
    " - display a histogram of the posterior for the transformed parameter, too.\n",
    " - report estimates of the mean, 5th and 95th percentiles of the posterior of the unconstrained $\\theta$\n",
    " - comment on whether your posterior mean is close to the frequentist estimator (which is the sample mean of your data, again).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
